When a presidential race that was supposed to be won by a mainstream moderate instead ends being captured by a far-right gadfly, you better believe pollsters are gonna get some scrutiny. But when this situation took place in the first round of French elections in 2002, bumping the incumbent prime minister from the final round, it wasn’t just the failure of prediction that led to a polling protest. Instead, people were concerned that opinion polling, itself, had caused the outcome.
Twenty-four years earlier, France had muzzled opinion polling, banning the publication of poll results for a week before any election out of fear that voters were following the polls, rather than the other way around. That changed in 2001, and the 2002 election was the first time since the 1970s that French voters had been able to make their choice knowing what their neighbors were likely planning to do.
As hard as it may be for some of us to imagine (especially readers of this website), laws limiting when opinion polls can be published before an election are pretty common. Of the 216 countries whose election rules are tracked by the United Nations-backed Electoral Knowledge Network, 92 have some kind of regulated blackout period where polls cannot be published. Even after its 2002 rule change, France still has a 24-hour blackout period before the vote. Experts say most of these laws are based around the same premise: Polls can influence votes. If you know that most of your fellow citizens are planning to pick a specific candidate, you might decide to be part of the winning team. If you know the person you’d pick is so far ahead that there’s no chance of them losing, maybe you’ll chill out and stay home on election day.
Number of countries per opinion poll blackout duration
* “Not applicable” includes countries that have no regulations limiting the publication of polls, as well as countries that don’t conduct public polling and ones that don’t have elections.
Source: The ACE Electoral Knowledge Network
But despite the power this fear has to shape law and fuel media narratives, the evidence supporting it is complex. Polls probably do influence how people vote in some situations, experts say. But it’s not anything like a universal, definitive effect. What’s more, some of them told me they aren’t sure that would be a bad thing. The question isn’t just whether polls determine outcomes, it’s also a debate over how people should decide their vote.
Looking through the published research on how polling might influence elections, the first thing you find is that the risk has a name — “the bandwagon effect.” The second thing you find is that paper after paper seeks to figure out if the bandwagon effect is real. How could a thing have a name but still need proof of its existence? “It’s very difficult to get at and isolate this effect,” said Tom van der Meer, a professor of social and behavioral sciences at the University of Amsterdam in the Netherlands.
Like many social science questions where the outcome is often determined by interactions between more than one factor, this is not an easy effect to study. Laboratory settings tend to show a bandwagon effect in action, van der Meer said. But these are spaces where research subjects look at pretend poll results and place hypothetical votes, which may not reflect the real world. Observational studies — looking at the outcomes of real elections — are thickets of potential causal factors, nearly impossible to hack your way through. How do you determine whether it was the polls themselves that shifted the vote, or the polls that shaped media coverage that, in turn, shifted the vote? You can see the problem.
But, on the whole, experts say the bandwagon is real. How real, though, depends on the context. “Are we talking about turnout, voting for a particular candidate, support for an issue …?” said Todd Hartman, a professor of quantitative social science at the University of Sheffield in the United Kingdom. “Depending on what area you’re talking about, the effects are stronger or weaker.”
For example, in 2013, researchers used a change in French law to get an idea of the potential impact of polls on voter turnout. Prior to 2005, citizens of France who lived in territories west of the country didn’t get to vote until after the mainland election had ended. Thus, they had the chance to see exit polls before they even went to cast their ballots. That changed after 2005, so researchers could compare several years worth of elections and see how knowledge of the presumed winner changed voter behavior. The result: After 2005, there was a nearly 12 percentage point increase in voter turnout. Far more people in those overseas territories voted when they didn’t already know who the winner was — a finding that has big implications for countries like the United States, where time zone differences mean voters in one part of the country can see the completed exit polls from earlier in the day.
But the effects aren’t always that distinct. A different paper, published in 2016, involved a series of experiments that sorted more than 20,000 Dutch voters into groups that were then exposed to different kinds of polling data. Surveys showed that the people given just poll numbers didn’t change their vote intention at all — they looked no different than the group that received no polling information. But a third group, which was presented with a narrative-style interpretation of the polls showing one party gaining ground over time, did change their intended vote, becoming 2 percentage points more likely than the control group to vote for the party that was surging. That’s a small effect, but it could matter in a tight race.
Another study showed that American voters with strong partisan preferences alter their votes to conform to opinion poll results that show what their preferred party likes or doesn’t like — but won’t do the same to match overall American opinion. Likewise, while polls won’t affect every voter, they can, in aggregate, become self-fulfilling prophecies that heighten how people feel about a given issue.
But while the experts I spoke to generally agreed that bandwagon effects exist under certain conditions, they weren’t as certain about the implications of those effects and what, if anything, we should do about it. They even disagreed with themselves at times. “It’s a hard question,” said Neil Malhotra, professor of political economy at the Stanford Graduate School of Business.
On the one hand, he told me, you don’t want people making choices in elections based on the kind of herding behavior that leads to a mediocre restaurant having a line down the block for no reason other than that there’s always a line there. Sometimes, popularity isn’t actually a proxy for quality. On the other hand, polls can provide voters with valuable information that allows them to vote strategically, especially in primaries where you’re less likely to know a lot about the candidates. Say you’re a Democratic primary voter who likes both Amy Klobuchar and Pete Buttigieg. A poll can help you decide which of those two candidates is most likely to benefit from your vote.
Hartman was also conflicted. “People will use whatever information is available to them,” he said. “In an ideal democracy, we’d like to see people making decisions based on the issue platforms. But we also know that many voters are low-information voters, and they’re going to use whatever cues they can to sort out which candidate to vote for.” Those might be endorsements. It might be party affiliation. They might be poll results. In that sense, bandwagons aren’t exactly good or bad. They just exist.
Which means the media has a large role to play in how voters hear about which bandwagons to jump on. Van der Meer’s research on those Dutch voters suggests that raw information doesn’t seem to shift votes, but narratives about the information do. In that case, he said, the media needs to be extra careful how it presents polling data.
Which, of course, brings FiveThirtyEight into the mix. As a publication that presents a lot of polling data to the public, we’re as much a part of this story as we are reporters of it. Nate Silver, our editor in chief, certainly thinks about bandwagons. But he doesn’t consider them to be that big of a deal, he told me. That’s because Silver doesn’t really see the choice as being between poll-informed voting and policy-informed voting. “Without polling, there’s a vacuum filled by punditry and media assumptions,” he said. Banning polls doesn’t necessarily mean people vote smarter. In fact, from Silver’s perspective, it means they’re likely to vote even dumber — basing a choice on speculation instead of data.
In the end, the question of whether polls influence voters might be less important than the question of whether voters have a right to access information they want. Consider, again, the 2002 French election. Analysis after the fact suggests that polling results did make a difference in that upset — leading voters to assume a mainstream runoff was so certain that it was safe to cast a ballot for a more extremist candidate, just to send a message to the winners. If enough people do that, their assumptions about who the winners will be won’t be accurate.
But that outcome didn’t make the French switch back to a longer poll blackout. They couldn’t. That’s because the whole reason the blackout was shortened was that the country’s highest court found it to be an infringement of an article of the European Convention on Human Rights, which prevents public authorities from interfering with people sharing their opinions. Polls may well have changed the outcome of an election in France. But that was a choice the voters had the right to make.